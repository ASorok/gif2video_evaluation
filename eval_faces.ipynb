{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCDNET1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  temporal downsample by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article GIF: **30.02/0.857** GIF2VIDEO: **33.27/0.921**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval GIF: **28.44/0.848** GIF2VIDEO: **30.24/0.897**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.k = 0\n",
    "opts.tCrop=3\n",
    "opts.tStride=3\n",
    "\n",
    "\n",
    "\n",
    "opts.color_model1_file=\"pretrained/ccdnet1_nogan_faces_nodither_ep60.pt\"\n",
    "opts.color_model2_file=\"pretrained/ccdnet2_nogan_faces_nodither_ep50.pt\"\n",
    "iter_ch = 3*4 \n",
    "color_model2 = UNet.UNet(iter_ch, 3, ch=64)\n",
    "color_model2.load_state_dict(torch.load(opts.color_model2_file)[\"model_netG\"])\n",
    "color_model2 = nn.DataParallel(color_model2.eval().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized using [pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (104 of 104) |######################| Elapsed Time: 3:56:25 Time:  3:56:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate_Summary: Epoch [-01/050], {'PSNR': 30.241318035722173, 'PSNR_gif': 28.444571302612843, 'SSIM': 0.897538148310099, 'SSIM_gif': 0.84869989881724}\n"
     ]
    }
   ],
   "source": [
    "initModel = 'pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt'\n",
    "color_model1 = UNet.UNet(3, 3, ch=64)\n",
    "color_model1.load_state_dict(torch.load(opts.color_model1_file)[\"model_netG\"])\n",
    "color_model1 = nn.DataParallel(color_model1.eval().to(DEVICE))\n",
    "    \n",
    "_, evalLD = create_dataloader()\n",
    "model = create_model()\n",
    "initialize(model, initModel)\n",
    "evaluate(-1, evalLD, model, color_model1, color_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal downsample by 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article GIF: **29.01/0.842** GIF2VIDEO: **32.08/0.908** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval GIF: **27.67/0.833** GIF2VIDEO: **29.64/0.886**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.k = 0\n",
    "opts.tCrop=5\n",
    "opts.tStride=5\n",
    "\n",
    "\n",
    "\n",
    "opts.color_model1_file=\"pretrained/ccdnet1_nogan_faces_nodither_ep60.pt\"\n",
    "opts.color_model2_file=\"pretrained/ccdnet2_nogan_faces_nodither_ep50.pt\"\n",
    "iter_ch = 3*4 \n",
    "color_model2 = UNet.UNet(iter_ch, 3, ch=64)\n",
    "color_model2.load_state_dict(torch.load(opts.color_model2_file)[\"model_netG\"])\n",
    "color_model2 = nn.DataParallel(color_model2.eval().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized using [pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (104 of 104) |######################| Elapsed Time: 3:12:12 Time:  3:12:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate_Summary: Epoch [-01/050], {'PSNR': 29.6419935298467, 'PSNR_gif': 27.677841905736233, 'SSIM': 0.8863477480081212, 'SSIM_gif': 0.8339242427702989}\n"
     ]
    }
   ],
   "source": [
    "initModel = 'pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt'\n",
    "color_model1 = UNet.UNet(3, 3, ch=64)\n",
    "color_model1.load_state_dict(torch.load(opts.color_model1_file)[\"model_netG\"])\n",
    "color_model1 = nn.DataParallel(color_model1.eval().to(DEVICE))\n",
    "    \n",
    "_, evalLD = create_dataloader()\n",
    "model = create_model()\n",
    "initialize(model, initModel)\n",
    "evaluate(-1, evalLD, model, color_model1, color_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal downsample by 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article GIF: **27.41/0.815** GIF2VIDEO: **30.20/0.884**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval GIF: **26.41/0.807** GIF2VIDEO: **28.43/0.864**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.k = 0\n",
    "opts.tCrop=9\n",
    "opts.tStride=9\n",
    "\n",
    "\n",
    "\n",
    "opts.color_model1_file=\"pretrained/ccdnet1_nogan_faces_nodither_ep60.pt\"\n",
    "opts.color_model2_file=\"pretrained/ccdnet2_nogan_faces_nodither_ep50.pt\"\n",
    "iter_ch = 3*4 \n",
    "color_model2 = UNet.UNet(iter_ch, 3, ch=64)\n",
    "color_model2.load_state_dict(torch.load(opts.color_model2_file)[\"model_netG\"])\n",
    "color_model2 = nn.DataParallel(color_model2.eval().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized using [pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (104 of 104) |######################| Elapsed Time: 3:01:02 Time:  3:01:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate_Summary: Epoch [-01/050], {'PSNR': 28.43812263117684, 'PSNR_gif': 26.41763749862529, 'SSIM': 0.8642844204477385, 'SSIM_gif': 0.8076317006552733}\n"
     ]
    }
   ],
   "source": [
    "initModel = 'pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt'\n",
    "color_model1 = UNet.UNet(3, 3, ch=64)\n",
    "color_model1.load_state_dict(torch.load(opts.color_model1_file)[\"model_netG\"])\n",
    "color_model1 = nn.DataParallel(color_model1.eval().to(DEVICE))\n",
    "    \n",
    "_, evalLD = create_dataloader()\n",
    "model = create_model()\n",
    "initialize(model, initModel)\n",
    "evaluate(-1, evalLD, model, color_model1, color_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCDNET2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal downsample by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article GIF: **30.02/0.857** GIF2VIDEO: **33.27/0.921**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval GIF: **28.44/0.848** GIF2VIDEO: **30.92/0.904**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.k = 1\n",
    "opts.tCrop=3\n",
    "opts.tStride=3\n",
    "\n",
    "\n",
    "\n",
    "opts.color_model1_file=\"pretrained/ccdnet1_nogan_faces_nodither_ep60.pt\"\n",
    "opts.color_model2_file=\"pretrained/ccdnet2_nogan_faces_nodither_ep50.pt\"\n",
    "iter_ch = 3*4 \n",
    "color_model2 = UNet.UNet(iter_ch, 3, ch=64)\n",
    "color_model2.load_state_dict(torch.load(opts.color_model2_file)[\"model_netG\"])\n",
    "color_model2 = nn.DataParallel(color_model2.eval().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized using [pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (104 of 104) |######################| Elapsed Time: 5:12:15 Time:  5:12:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate_Summary: Epoch [-01/050], {'PSNR': 30.926401265357768, 'PSNR_gif': 28.444571302612843, 'SSIM': 0.9047281324313237, 'SSIM_gif': 0.84869989881724}\n"
     ]
    }
   ],
   "source": [
    "initModel = 'pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt'\n",
    "color_model1 = UNet.UNet(3, 3, ch=64)\n",
    "color_model1.load_state_dict(torch.load(opts.color_model1_file)[\"model_netG\"])\n",
    "color_model1 = nn.DataParallel(color_model1.eval().to(DEVICE))\n",
    "    \n",
    "_, evalLD = create_dataloader()\n",
    "model = create_model()\n",
    "initialize(model, initModel)\n",
    "evaluate(-1, evalLD, model, color_model1, color_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal downsample by 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article GIF: **29.01/0.842** GIF2VIDEO: **32.08/0.908** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval GIF: **27.67/0.833** GIF2VIDEO: **30.10/0.891**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.k = 1\n",
    "opts.tCrop=5\n",
    "opts.tStride=5\n",
    "\n",
    "\n",
    "\n",
    "opts.color_model1_file=\"pretrained/ccdnet1_nogan_faces_nodither_ep60.pt\"\n",
    "opts.color_model2_file=\"pretrained/ccdnet2_nogan_faces_nodither_ep50.pt\"\n",
    "iter_ch = 3*4 \n",
    "color_model2 = UNet.UNet(iter_ch, 3, ch=64)\n",
    "color_model2.load_state_dict(torch.load(opts.color_model2_file)[\"model_netG\"])\n",
    "color_model2 = nn.DataParallel(color_model2.eval().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized using [pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (104 of 104) |######################| Elapsed Time: 3:49:00 Time:  3:49:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate_Summary: Epoch [-01/050], {'PSNR': 30.10371584546901, 'PSNR_gif': 27.677841905736233, 'SSIM': 0.8913979553033549, 'SSIM_gif': 0.8339242427702989}\n"
     ]
    }
   ],
   "source": [
    "initModel = 'pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt'\n",
    "color_model1 = UNet.UNet(3, 3, ch=64)\n",
    "color_model1.load_state_dict(torch.load(opts.color_model1_file)[\"model_netG\"])\n",
    "color_model1 = nn.DataParallel(color_model1.eval().to(DEVICE))\n",
    "    \n",
    "_, evalLD = create_dataloader()\n",
    "model = create_model()\n",
    "initialize(model, initModel)\n",
    "evaluate(-1, evalLD, model, color_model1, color_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal downsample by 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article GIF: **27.41/0.815** GIF2VIDEO: **30.20/0.884**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval GIF: **26.41/0.807** GIF2VIDEO: **28.722/0.867**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.k = 1\n",
    "opts.tCrop=9\n",
    "opts.tStride=9\n",
    "\n",
    "\n",
    "\n",
    "opts.color_model1_file=\"pretrained/ccdnet1_nogan_faces_nodither_ep60.pt\"\n",
    "opts.color_model2_file=\"pretrained/ccdnet2_nogan_faces_nodither_ep50.pt\"\n",
    "iter_ch = 3*4 \n",
    "color_model2 = UNet.UNet(iter_ch, 3, ch=64)\n",
    "color_model2.load_state_dict(torch.load(opts.color_model2_file)[\"model_netG\"])\n",
    "color_model2 = nn.DataParallel(color_model2.eval().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized using [pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (104 of 104) |######################| Elapsed Time: 3:18:48 Time:  3:18:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate_Summary: Epoch [-01/050], {'PSNR': 28.722180573194382, 'PSNR_gif': 26.41763749862529, 'SSIM': 0.867860711080466, 'SSIM_gif': 0.8076317006552733}\n"
     ]
    }
   ],
   "source": [
    "initModel = 'pretrained/gif2video_t8.ccdnet1_gan_faces_nodither_ep30.pt'\n",
    "color_model1 = UNet.UNet(3, 3, ch=64)\n",
    "color_model1.load_state_dict(torch.load(opts.color_model1_file)[\"model_netG\"])\n",
    "color_model1 = nn.DataParallel(color_model1.eval().to(DEVICE))\n",
    "    \n",
    "_, evalLD = create_dataloader()\n",
    "model = create_model()\n",
    "initialize(model, initModel)\n",
    "evaluate(-1, evalLD, model, color_model1, color_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
